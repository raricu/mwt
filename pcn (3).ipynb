{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3f72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['export OPENBLAS_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25af8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "from torch import Tensor\n",
    "from typing import List, Tuple\n",
    "from models.models import MWT2d\n",
    "from models.utils import train, test, LpLoss, get_filter, UnitGaussianNormalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import cv2\n",
    "import glob\n",
    "from functools import partial\n",
    "import matplotlib as ml\n",
    "from PIL import Image\n",
    "from models.utils_3d import train, test, LpLoss, get_filter, UnitGaussianNormalizer\n",
    "import operator\n",
    "from functools import reduce\n",
    "from timeit import default_timer\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import pickle\n",
    "import tqdm\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bcdd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae09eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fd6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(name):\n",
    "    \n",
    "    if name == 'xavier_normal':\n",
    "        init_ = partial(nn.init.xavier_normal_)\n",
    "    elif name == 'kaiming_uniform':\n",
    "        init_ = partial(nn.init.kaiming_uniform_)\n",
    "    elif name == 'kaiming_normal':\n",
    "        init_ = partial(nn.init.kaiming_normal_)\n",
    "    return init_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70daea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1\n",
    "h = int(((64 - 1)/r) + 1)\n",
    "s = h\n",
    "\n",
    "dataloader = np.load('Data/2D_new.npy')\n",
    "u_data = dataloader.astype(np.float32)\n",
    "x_train = torch.from_numpy(u_data[:170, ::r,::r, 0])\n",
    "y_train = torch.from_numpy(u_data[:170, ::r,::r, 1])\n",
    "x_test = torch.from_numpy(u_data[-30:, ::r,::r, 0])\n",
    "y_test = torch.from_numpy(u_data[-30:, ::r,::r, 1])\n",
    "x_normalizer = UnitGaussianNormalizer(x_train)\n",
    "x_train = x_normalizer.encode(x_train)\n",
    "x_test = x_normalizer.encode(x_test)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(y_train)\n",
    "y_train = y_normalizer.encode(y_train)\n",
    "\n",
    "ich = 3\n",
    "initializer = get_initializer('xavier_normal') # xavier_normal, kaiming_normal, kaiming_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd50763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MWT2d(ich, \n",
    "            alpha = 12,\n",
    "            c = 4,\n",
    "            k = 4, \n",
    "            base = 'legendre', # 'chebyshev'\n",
    "            nCZ = 4,\n",
    "            L = 0,\n",
    "            initializer = initializer,\n",
    "            ).to(device)\n",
    "learning_rate = 0.001\n",
    "epochs = 2000\n",
    "step_size = 100\n",
    "gamma = 0.5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "myloss = LpLoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c378aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(melt, temp):\n",
    "    a = np.empty((64, 64))\n",
    "    rows= np.linspace(melt*100, temp, a.shape[1])\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i, :] = np.ones(a.shape[1])*rows[i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aac393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier(u):\n",
    "    \n",
    "    melt = u[0]\n",
    "    temp = u[1]\n",
    "    data = create_matrix(u[0], u[1])\n",
    "    data = np.reshape(data, (1, data.shape[0], data.shape[1]))\n",
    "    x_test = data.astype(np.float32)\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    \n",
    "    x_test = x_normalizer.encode(x_test)\n",
    "    grids = []\n",
    "    grids.append(np.linspace(0, 1, s))\n",
    "    grids.append(np.linspace(0, 1, s))\n",
    "    grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "    grid = grid.reshape(1,s,s,2)\n",
    "    grid = torch.tensor(grid, dtype=torch.float)\n",
    "    x_test = torch.cat([x_test.reshape(1,s,s,1), grid.repeat(1,1,1,1)], dim=3)\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "    \n",
    "    checkpoint = torch.load('NS_models/final_exp/altered_model1200.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    model.eval()\n",
    "    y_normalizer.cuda()\n",
    "\n",
    "\n",
    "    pred = torch.zeros(x_test[:, :, :, 0].shape)\n",
    "    post_proc=y_normalizer.decode\n",
    "    index = 0\n",
    "    test_loader = torch.utils.data.DataLoader(x_test, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            output = post_proc(out)\n",
    "            pred[index] = output\n",
    "            return pred[index].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5229b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel(x, y):\n",
    "    # print(x.shape)\n",
    "    # print(y.shape)\n",
    "#     l = x.shape[0]*x.shape[1]\n",
    "    # L2 norm\n",
    "#     diff_norms = np.linalg.norm(x.reshape((1,l)) - y.reshape((1,l)))\n",
    "    diff = x - y\n",
    "    return np.linalg.norm(diff, ord = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f03934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(y, f, sigma):\n",
    "    l2_total = math.pow(rel(y, f),2)\n",
    "    \n",
    "    scale = 1 #0.000001\n",
    "    return -0.5*l2_total/(math.pow(sigma,2))*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62d6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcn(y, n_iters, beta, sigma):\n",
    "    \"\"\" pCN MCMC method for sampling from pdf defined by log_prior and log_likelihood.\n",
    "    Inputs:\n",
    "        log_likelihood - log-likelihood function\n",
    "        u0 - initial sample\n",
    "        y - observed data\n",
    "        n_iters - number of samples\n",
    "        beta - step-size parameter\n",
    "    Returns:\n",
    "        X - samples from target distribution\n",
    "        acc/n_iters - the proportion of accepted samples\"\"\"\n",
    "    np.random.seed(14235)\n",
    "    X = []\n",
    "    acc = 0\n",
    "    melt = 5 #1.5\n",
    "    temp = 273\n",
    "    mean = (melt, temp)\n",
    "    cov = [[1, 0], [0, 1]]\n",
    "    u0 = np.random.multivariate_normal(mean, cov)\n",
    "    u_prev = u0\n",
    "\n",
    "    ll_prev = log_likelihood(y, fourier(u_prev), sigma)\n",
    "    print(f\"Initial proposal: {u_prev}\")\n",
    "    u_new = np.ones(u_prev.shape)\n",
    "    count = 0\n",
    "    for i in tqdm.trange(n_iters):\n",
    "#         print(\"beta: \", beta)\n",
    "        xi = np.random.multivariate_normal((0, 0), cov)\n",
    "        u_new = np.sqrt(1-beta**2)*u_prev + beta * xi # Propose new sample using pCN proposal\n",
    "#         print(\"xi:\", xi)\n",
    "#         print('u_prev:', u_prev)\n",
    "#         print('u_new:', u_new)\n",
    "\n",
    "        ll_new = log_likelihood(y, fourier(u_new), sigma)\n",
    "\n",
    "        # Calculate pCN acceptance probability\n",
    "        log_alpha = min(0, ll_new-ll_prev) \n",
    "        log_u = np.log(np.random.random())\n",
    "#         print('ll_prev: ', ll_prev)\n",
    "#         print('ll_new: ', ll_new)\n",
    "#         print('log_u < log_alpha: ', log_u < log_alpha)\n",
    "#         print('log_alpha: ', log_alpha)\n",
    "#         print('log_u: ' , log_u)\n",
    "#         print('beta: ', beta)\n",
    "        accept = log_u<=log_alpha # Compare log_alpha and log_u to accept/reject sample (accept should be boolean)\n",
    "        if accept:\n",
    "            acc += 1\n",
    "            X.append(u_new)\n",
    "            u_prev = u_new\n",
    "            ll_prev = ll_new\n",
    "#             beta = min(1, 1.001*beta)\n",
    "\n",
    "            count = count-1\n",
    "#             if count > 50:\n",
    "#                 print(\"Proposal: \", u_new)\n",
    "#                 print(f\"log-likelihood is: {ll_new}\")\n",
    "#                 beta = 0.2\n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "        else:\n",
    "            X.append(u_prev)\n",
    "#             beta = max(0.001, 0.5*beta)\n",
    "            count = count+1\n",
    "#             if count > 50:\n",
    "# #                 print(\"Proposal: \", u_new)\n",
    "# #                 print(f\"log-likelihood is: {ll_new}\")\n",
    "#                 beta = 0.0001\n",
    "#                 count = 0\n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "#         if count > 200:\n",
    "#             print(\"Proposal: \", u_new)\n",
    "#             print(f\"log-likelihood is: {ll_new}\")\n",
    "#             break\n",
    "#         else:\n",
    "#             pass\n",
    "    return X, acc / n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65cd341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "y = np.load('Data/2D_altered.npy')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e7c921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  101\n",
      "parameters:  0.5336842105263158 246.05263157894737\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_594684/3049754066.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_test = torch.tensor(x_test, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial proposal: [  5.86504661 274.79227837]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 29/300000 [00:08<24:49:39,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, y[k, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], y[k, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m , \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(observed_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 14\u001b[0m pcn_u, pcn_acc \u001b[38;5;241m=\u001b[39m \u001b[43mpcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m pcn_u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pcn_u)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcceptance rate: \u001b[39m\u001b[38;5;124m\"\u001b[39m, pcn_acc)\n",
      "Cell \u001b[0;32mIn [12], line 34\u001b[0m, in \u001b[0;36mpcn\u001b[0;34m(y, n_iters, beta, sigma)\u001b[0m\n\u001b[1;32m     29\u001b[0m         u_new \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mu_prev \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m xi \u001b[38;5;66;03m# Propose new sample using pCN proposal\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#         print(\"xi:\", xi)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#         print('u_prev:', u_prev)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#         print('u_new:', u_new)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m         ll_new \u001b[38;5;241m=\u001b[39m log_likelihood(y, \u001b[43mfourier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_new\u001b[49m\u001b[43m)\u001b[49m, sigma)\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# Calculate pCN acceptance probability\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         log_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m0\u001b[39m, ll_new\u001b[38;5;241m-\u001b[39mll_prev) \n",
      "Cell \u001b[0;32mIn [9], line 20\u001b[0m, in \u001b[0;36mfourier\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     17\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,s,s,\u001b[38;5;241m1\u001b[39m), grid\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     18\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m---> 20\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNS_models/final_exp/altered_model1200.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1100\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:1083\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1079\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39muntyped()\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1083\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1084\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:187\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py:83\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[43muntyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run MCMC\n",
    "n_iters = 300000\n",
    "beta = 0.02\n",
    "\n",
    "# Likelihood variance\n",
    "sigma = 1\n",
    "\n",
    "simulations = []\n",
    "for k in range(101, y.shape[0]):\n",
    "    print(\"Step: \", k)\n",
    "    observed_data = y[k, : , :, 1]\n",
    "    print(\"parameters: \", y[k, 0, 0, 0], y[k, -1 , -1, 0])\n",
    "    print(observed_data.shape)\n",
    "    pcn_u, pcn_acc = pcn(observed_data, n_iters, beta, sigma)\n",
    "    pcn_u = np.array(pcn_u)\n",
    "    print(\"Acceptance rate: \", pcn_acc)\n",
    "    simulations.append(pcn_u)\n",
    "    np.save('simulations/2D/sim{}.npy'.format(k), pcn_u)\n",
    "simulations = np.array(simulations)\n",
    "np.save('simulations/2D/sim.npy', simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79335fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier([0.5336842105263158, 246.05263157894737])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier([3.5, 244])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798817bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
