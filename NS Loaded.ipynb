{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f71c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['export OPENBLAS_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266cbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import cv2\n",
    "import glob\n",
    "from functools import partial\n",
    "import matplotlib as ml\n",
    "from PIL import Image\n",
    "# from models.utils import train, test, LpLoss, get_filter, UnitGaussianNormalizer\n",
    "from models.utils_3d import train, test, LpLoss, get_filter, UnitGaussianNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab57644",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08149f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6150b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(name):\n",
    "    \n",
    "    if name == 'xavier_normal':\n",
    "        init_ = partial(nn.init.xavier_normal_)\n",
    "    elif name == 'kaiming_uniform':\n",
    "        init_ = partial(nn.init.kaiming_uniform_)\n",
    "    elif name == 'kaiming_normal':\n",
    "        init_ = partial(nn.init.kaiming_normal_)\n",
    "    return init_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19940dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseKernel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1, \n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernel,self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.conv = self.convBlock(alpha*k**2, alpha*k**2)\n",
    "        self.Lo = nn.Conv1d(alpha*k**2, c*k**2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, ich, Nx, Ny, T)\n",
    "        x = x.reshape(B, -1, Nx, Ny, T)\n",
    "        x = self.conv(x)\n",
    "        x = self.Lo(x.view(B, c*ich, -1)).view(B, c, ich, Nx, Ny, T)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def convBlock(self, ich, och):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv3d(och, och, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return net \n",
    "    \n",
    "\n",
    "def compl_mul3d(a, b):\n",
    "    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "    op = partial(torch.einsum, \"bixyz,ioxyz->boxyz\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "\n",
    "# fft conv taken from: https://github.com/zongyi-li/fourier_neural_operator\n",
    "class sparseKernelFT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1, \n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernelFT, self).__init__()        \n",
    "        \n",
    "        self.modes = alpha\n",
    "\n",
    "        self.weights1 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))\n",
    "        self.weights2 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))        \n",
    "        self.weights3 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))        \n",
    "        self.weights4 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))        \n",
    "        nn.init.xavier_normal_(self.weights1)\n",
    "        nn.init.xavier_normal_(self.weights2)\n",
    "        nn.init.xavier_normal_(self.weights3)\n",
    "        nn.init.xavier_normal_(self.weights4)\n",
    "        \n",
    "        self.Lo = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "#         self.Wo = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(\"x.shape before\", x.shape)\n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, ich, N, N, T)\n",
    "        \n",
    "        x = x.reshape(B, -1, Nx, Ny, T)\n",
    "#         print(\"x.shape \", x.shape)\n",
    "        x_fft = torch.rfft(x, 3, normalized=True, onesided=True)\n",
    "        \n",
    "        # Multiply relevant Fourier modes\n",
    "        l1 = min(self.modes, Nx//2+1)\n",
    "#         print(\"l1 \", l1)\n",
    "        l2 = min(self.modes, Ny//2+1)\n",
    "#         print(\"l2 \", l2)\n",
    "        out_ft = torch.zeros(B, c*ich, Nx, Ny, T//2 +1, 2, device=x.device)\n",
    "\n",
    "#         print(\"out_ft\", out_ft.shape)\n",
    "#         print(\"x_fft\", x_fft.shape)\n",
    "#         print(\"self.modes \", self.modes)\n",
    "#         print(\"self.weights1 \", self.weights1.shape)\n",
    "        \n",
    "        out_ft[:, :, :l1, :l2, :self.modes] = compl_mul3d(\n",
    "            x_fft[:, :, :l1, :l2, :self.modes], self.weights1[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, -l1:, :l2, :self.modes] = compl_mul3d(\n",
    "                x_fft[:, :, -l1:, :l2, :self.modes], self.weights2[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, :l1, -l2:, :self.modes] = compl_mul3d(\n",
    "                x_fft[:, :, :l1, -l2:, :self.modes], self.weights3[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, -l1:, -l2:, :self.modes] = compl_mul3d(\n",
    "                x_fft[:, :, -l1:, -l2:, :self.modes], self.weights4[:, :, :l1, :l2, :])\n",
    "        \n",
    "        #Return to physical space\n",
    "        x = torch.irfft(out_ft, 3, normalized=True, onesided=True, signal_sizes=(Nx, Ny, T))\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.Lo(x.view(B, c*ich, -1)).view(B, c, ich, Nx, Ny, T)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "class MWT_CZ(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k = 3, alpha = 5, \n",
    "                 L = 0, c = 1,\n",
    "                 base = 'legendre',\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(MWT_CZ, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0@PHI0\n",
    "        G0r = G0@PHI0\n",
    "        H1r = H1@PHI1\n",
    "        G1r = G1@PHI1\n",
    "        \n",
    "        H0r[np.abs(H0r)<1e-8]=0\n",
    "        H1r[np.abs(H1r)<1e-8]=0\n",
    "        G0r[np.abs(G0r)<1e-8]=0\n",
    "        G1r[np.abs(G1r)<1e-8]=0\n",
    "        \n",
    "        self.A = sparseKernelFT(k, alpha, c)\n",
    "        self.B = sparseKernelFT(k, alpha, c)\n",
    "        self.C = sparseKernelFT(k, alpha, c)\n",
    "        \n",
    "        self.T0 = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "\n",
    "        if initializer is not None:\n",
    "            self.reset_parameters(initializer)\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0, H0).T, \n",
    "                            np.kron(H0, H1).T,\n",
    "                            np.kron(H1, H0).T,\n",
    "                            np.kron(H1, H1).T,\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((np.kron(G0, G0).T,\n",
    "                            np.kron(G0, G1).T,\n",
    "                            np.kron(G1, G0).T,\n",
    "                            np.kron(G1, G1).T,\n",
    "                           ), axis=0)))\n",
    "        \n",
    "        self.register_buffer('rc_ee', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0r, H0r), \n",
    "                            np.kron(G0r, G0r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_eo', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0r, H1r), \n",
    "                            np.kron(G0r, G1r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_oe', torch.Tensor(\n",
    "            np.concatenate((np.kron(H1r, H0r), \n",
    "                            np.kron(G1r, G0r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_oo', torch.Tensor(\n",
    "            np.concatenate((np.kron(H1r, H1r), \n",
    "                            np.kron(G1r, G1r),\n",
    "                           ), axis=0)))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, k^2, Nx, Ny, T)\n",
    "        ns = math.floor(np.log2(Nx))\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "#         decompose\n",
    "        for i in range(ns-self.L):\n",
    "            d, x = self.wavelet_transform(x)\n",
    "            Ud += [self.A(d) + self.B(x)]\n",
    "            Us += [self.C(d)]\n",
    "        x = self.T0(x.reshape(B, c*ich, -1)).view(\n",
    "            B, c, ich, 2**self.L, 2**self.L, T) # coarsest scale transform\n",
    "\n",
    "#        reconstruct            \n",
    "        for i in range(ns-1-self.L,-1,-1):\n",
    "            x = x + Us[i]\n",
    "            x = torch.cat((x, Ud[i]), 2)\n",
    "            x = self.evenOdd(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, :, :, ::2 , ::2 , :], \n",
    "                        x[:, :, :, ::2 , 1::2, :], \n",
    "                        x[:, :, :, 1::2, ::2 , :], \n",
    "                        x[:, :, :, 1::2, 1::2, :]\n",
    "                       ], 2)\n",
    "        waveFil = partial(torch.einsum, 'bcixyt,io->bcoxyt') \n",
    "        d = waveFil(xa, self.ec_d)\n",
    "        s = waveFil(xa, self.ec_s)\n",
    "        return d, s\n",
    "        \n",
    "        \n",
    "    def evenOdd(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, 2*k^2, Nx, Ny)\n",
    "        assert ich == 2*self.k**2\n",
    "        evOd = partial(torch.einsum, 'bcixyt,io->bcoxyt')\n",
    "        x_ee = evOd(x, self.rc_ee)\n",
    "        x_eo = evOd(x, self.rc_eo)\n",
    "        x_oe = evOd(x, self.rc_oe)\n",
    "        x_oo = evOd(x, self.rc_oo)\n",
    "        \n",
    "        x = torch.zeros(B, c, self.k**2, Nx*2, Ny*2, T,\n",
    "            device = x.device)\n",
    "        x[:, :, :, ::2 , ::2 , :] = x_ee\n",
    "        x[:, :, :, ::2 , 1::2, :] = x_eo\n",
    "        x[:, :, :, 1::2, ::2 , :] = x_oe\n",
    "        x[:, :, :, 1::2, 1::2, :] = x_oo\n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self, initializer):\n",
    "        initializer(self.T0.weight)\n",
    "    \n",
    "    \n",
    "class MWT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ich = 1, k = 3, alpha = 2, c = 1,\n",
    "                 nCZ = 3,\n",
    "                 L = 0,\n",
    "                 base = 'legendre',\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(MWT,self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.L = L\n",
    "        self.nCZ = nCZ\n",
    "        self.Lk = nn.Linear(ich, c*k**2)\n",
    "        \n",
    "        self.MWT_CZ = nn.ModuleList(\n",
    "            [MWT_CZ(k, alpha, L, c, base, \n",
    "            initializer) for _ in range(nCZ)]\n",
    "        )\n",
    "        self.BN = nn.ModuleList(\n",
    "            [nn.BatchNorm3d(c*k**2) for _ in range(nCZ)]\n",
    "        )\n",
    "        self.Lc0 = nn.Linear(c*k**2, 128)\n",
    "        self.Lc1 = nn.Linear(128, 1)\n",
    "        \n",
    "        if initializer is not None:\n",
    "            self.reset_parameters(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, Nx, Ny, T, ich = x.shape # (B, Nx, Ny, T, d)\n",
    "        ns = math.floor(np.log2(Nx))\n",
    "        x = model.Lk(x)\n",
    "        x = x.view(B, Nx, Ny, T, self.c, self.k**2)\n",
    "        x = x.permute(0, 4, 5, 1, 2, 3)\n",
    "    \n",
    "        for i in range(self.nCZ):\n",
    "            x = self.MWT_CZ[i](x)\n",
    "            x = self.BN[i](x.view(B, -1, Nx, Ny, T)).view(\n",
    "                B, self.c, self.k**2, Nx, Ny, T)\n",
    "            if i < self.nCZ-1:\n",
    "                x = F.relu(x)\n",
    "\n",
    "        x = x.view(B, -1, Nx, Ny, T) # collapse c and k**2\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = self.Lc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.Lc1(x)\n",
    "        return x.squeeze()\n",
    "    \n",
    "    def reset_parameters(self, initializer):\n",
    "        initializer(self.Lc0.weight)\n",
    "        initializer(self.Lc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d74f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVid(tensor, set, dirPath):\n",
    "    \n",
    "    newDir = 'train{}'.format(set)\n",
    "    path = os.path.join(dirPath, newDir)\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    for i in range(tensor.shape[-1]):\n",
    "        f = tensor[set][:, :, i]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(f, interpolation='nearest')\n",
    "        cbar = fig.colorbar(cax)\n",
    "        \n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        cbar.set_label('Vorticity (RPM)', rotation=270)\n",
    "        ax.set_title('Two-dimensional Vorticity')\n",
    "        plt.savefig(path+'/{}.png'.format(i))\n",
    "    \n",
    "    img_array = []\n",
    "    filelist = glob.glob(path+'/*.png')\n",
    "    \n",
    "    for filename in sorted(filelist):\n",
    "        img = cv2.imread(filename)\n",
    "        print(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "    \n",
    "    fps = 1\n",
    "    vids = os.path.join(dirPath, 'videos')\n",
    "    if os.path.isdir(vids):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(vids)\n",
    "\n",
    "    vidpath = vids+'/Vid{}.mp4'.format(set)\n",
    "    out = cv2.VideoWriter(vidpath ,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "    for j in range(len(img_array)):\n",
    "        out.write(img_array[j])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a6b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(initial, prediction, test, index, timestep):\n",
    "#     initial = initial.mean(4)[index][:, :, timestep].T\n",
    "#     test = test[index][:, :, timestep].T\n",
    "#     prediction = prediction[index][:, :, timestep].T\n",
    "    \n",
    "    loss = abs(torch.sub(test, prediction))\n",
    "    test0 = test[index][:, :, 0].T\n",
    "    prediction0 = prediction[index][:, :, 0].T\n",
    "    loss0 = abs(torch.sub(test0, prediction0))\n",
    "    print(test.shape)\n",
    "    test39 = test[index][:, :, 39].T\n",
    "    prediction39 = prediction[index][:, :, 39].T\n",
    "    loss39 = abs(torch.sub(test39, prediction39))\n",
    "#     print(test)\n",
    "#     print(prediction)\n",
    "#     print(loss)\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(25, 20))\n",
    "\n",
    "    cp1 = axs[0, 0].matshow(test0)\n",
    "    axs[0, 0].set_title('Beginning of true field', fontsize=20)\n",
    "    axs[0, 0].xaxis.set_tick_params(labelsize=18)\n",
    "    axs[0, 0].yaxis.set_tick_params(labelsize=18)\n",
    "    cp1 = fig.colorbar(cp1)\n",
    "    cp1.ax.tick_params(labelsize=18)\n",
    "    \n",
    "    cp2 = axs[0, 1].matshow(test39)\n",
    "    axs[0, 1].set_title('End of true field', fontsize=20)\n",
    "    axs[0, 1].xaxis.set_tick_params(labelsize=18)\n",
    "    axs[0, 1].yaxis.set_tick_params(labelsize=18)\n",
    "    cp2 = fig.colorbar(cp2)\n",
    "    cp2.ax.tick_params(labelsize=18)\n",
    "    \n",
    "    cp3 = axs[1, 0].matshow(prediction0)\n",
    "    axs[1, 0].set_title('Beginning of predicted field', fontsize=20)\n",
    "    axs[1, 0].xaxis.set_tick_params(labelsize=18)\n",
    "    axs[1, 0].yaxis.set_tick_params(labelsize=18)\n",
    "    cp3 = fig.colorbar(cp3)\n",
    "    cp3.ax.tick_params(labelsize=18)\n",
    "    \n",
    "    cp4 = axs[1, 1].matshow(prediction39)\n",
    "    axs[1, 1].set_title('End of predicted field', fontsize=20)\n",
    "    axs[1, 1].xaxis.set_tick_params(labelsize=18)\n",
    "    axs[1, 1].yaxis.set_tick_params(labelsize=18)\n",
    "    cp4 = fig.colorbar(cp4)\n",
    "    cp4.ax.tick_params(labelsize=18)\n",
    "    \n",
    "    cp5 = axs[2, 0].matshow(loss0)\n",
    "    axs[2, 0].set_title('Loss at the beginning', fontsize=20)\n",
    "    axs[2, 0].xaxis.set_tick_params(labelsize=18)\n",
    "    axs[2, 0].yaxis.set_tick_params(labelsize=18)\n",
    "    cp5 = fig.colorbar(cp5)\n",
    "    cp5.ax.tick_params(labelsize=18)\n",
    "    \n",
    "    cp6 = axs[2, 1].matshow(loss39)\n",
    "    axs[2, 1].set_title('Loss at the end', fontsize=20)\n",
    "    axs[2, 1].xaxis.set_tick_params(labelsize=18)\n",
    "    axs[2, 1].yaxis.set_tick_params(labelsize=18)\n",
    "    cp6 = fig.colorbar(cp6)\n",
    "    cp6.ax.tick_params(labelsize=18)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3d4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_loss(prediction, test, index, timestep):\n",
    "    test = test[index][:, :, timestep]\n",
    "    # prediction = torch.t(prediction[index][:, :, timestep])\n",
    "    prediction = prediction[index][:, :, timestep]\n",
    "    loss = torch.sub(test, prediction)\n",
    "    mean = torch.mean(loss)\n",
    "    std = torch.std(loss)\n",
    "    return torch.sub(loss, mean*torch.ones(loss.shape))/std, mean, std\n",
    "    # return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec164f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/ns_V1e-3_N5000_T50.mat'\n",
    "ntrain = 1000\n",
    "ntest = 200\n",
    "\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c20e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_path = 'Data/data_reshaped/64/data_total.npy'\n",
    "# data_path = 'Data/melt/melting.npy'\n",
    "\n",
    "# ntrain = 170\n",
    "# ntest = 30\n",
    "\n",
    "# batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fafc12f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 64, 64, 10])\n",
      "torch.Size([1000, 64, 64, 40])\n",
      "torch.Size([200, 64, 64, 10])\n",
      "torch.Size([200, 64, 64, 40])\n"
     ]
    }
   ],
   "source": [
    "sub = 1\n",
    "S = 64 // sub\n",
    "T_in = 10\n",
    "T = 40\n",
    "\n",
    "dataloader = h5py.File(data_path)\n",
    "u_data = dataloader['u']\n",
    "t_data = dataloader['t']\n",
    "\n",
    "# dataloader = np.load(data_path).T\n",
    "# print(dataloader.shape)\n",
    "# u_data = dataloader\n",
    "# t_data = np.linspace(0., 2.5, 50)\n",
    "\n",
    "\n",
    "train_a = torch.from_numpy(u_data[:T_in, ::sub,::sub,:ntrain]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "train_u = torch.from_numpy(u_data[T_in:T_in+T, ::sub,::sub,:ntrain]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "\n",
    "test_a = torch.from_numpy(u_data[:T_in, ::sub,::sub,-ntest:]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "test_u = torch.from_numpy(u_data[T_in:T_in+T, ::sub,::sub,-ntest:]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "\n",
    "\n",
    "print(train_a.shape)\n",
    "print(train_u.shape)\n",
    "print(test_a.shape)\n",
    "print(test_u.shape)\n",
    "assert(S == train_u.shape[-2])\n",
    "assert(T == train_u.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9108c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 64, 64, 40])\n",
      "x_train shape before =  torch.Size([1000, 64, 64, 10])\n",
      "x_test shape before =  torch.Size([200, 64, 64, 10])\n",
      "x_train shape after =  torch.Size([1000, 64, 64, 40, 10])\n",
      "x_test shape after =  torch.Size([200, 64, 64, 40, 10])\n"
     ]
    }
   ],
   "source": [
    "a_normalizer = UnitGaussianNormalizer(train_a)\n",
    "x_train0 = a_normalizer.encode(train_a)\n",
    "x_test0 = a_normalizer.encode(test_a)\n",
    "\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(train_u)\n",
    "y_train = y_normalizer.encode(train_u)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print('x_train shape before = ', x_train0.shape)\n",
    "print('x_test shape before = ', x_test0.shape)\n",
    "\n",
    "x_train0 = x_train0.reshape(ntrain,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "x_test0 = x_test0.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "\n",
    "print('x_train shape after = ', x_train0.shape)\n",
    "print('x_test shape after = ', x_test0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2e95ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridx shape =  torch.Size([1, 64, 64, 40, 1])\n",
      "gridy shape =  torch.Size([1, 64, 64, 40, 1])\n",
      "gridt shape =  torch.Size([1, 64, 64, 40, 1])\n",
      "x_train shape before =  torch.Size([1000, 64, 64, 40, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_865490/1268453912.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train = torch.tensor(x_train, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape after =  torch.Size([1000, 64, 64, 40, 13])\n",
      "x_test shape before =  torch.Size([200, 64, 64, 40, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_865490/1268453912.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_test = torch.tensor(x_test, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape after =  torch.Size([200, 64, 64, 40, 13])\n"
     ]
    }
   ],
   "source": [
    "# pad locations (x,y,t)\n",
    "gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridx = gridx.reshape(1, S, 1, 1, 1).repeat([1, 1, S, T, 1])\n",
    "print('gridx shape = ', gridx.shape)\n",
    "gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridy = gridy.reshape(1, 1, S, 1, 1).repeat([1, S, 1, T, 1])\n",
    "print('gridy shape = ', gridy.shape)\n",
    "gridt = torch.tensor(np.linspace(0, 1, T+1)[1:], dtype=torch.float)\n",
    "gridt = gridt.reshape(1, 1, 1, T, 1).repeat([1, S, S, 1, 1])\n",
    "print('gridt shape = ',gridt.shape)\n",
    "\n",
    "print('x_train shape before = ', x_train0.shape)\n",
    "x_train = torch.cat((gridx.repeat([ntrain,1,1,1,1]), gridy.repeat([ntrain,1,1,1,1]),\n",
    "                       gridt.repeat([ntrain,1,1,1,1]), x_train0), dim=-1)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float)\n",
    "print('x_train shape after = ', x_train.shape)\n",
    "\n",
    "print('x_test shape before = ', x_test0.shape)\n",
    "x_test = torch.cat((gridx.repeat([ntest,1,1,1,1]), gridy.repeat([ntest,1,1,1,1]),\n",
    "                       gridt.repeat([ntest,1,1,1,1]), x_test0), dim=-1)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "print('x_test shape after = ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350016c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, test_u), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1056d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ich = 13\n",
    "initializer = get_initializer('xavier_normal') # xavier_normal, kaiming_normal, kaiming_uniform\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "alpha = 12\n",
    "c = 4\n",
    "k = 3\n",
    "nCZ = 4\n",
    "L = 0\n",
    "model = MWT(ich, \n",
    "            alpha = alpha,\n",
    "            c = c,\n",
    "            k = k, \n",
    "            base = 'legendre', # chebyshev\n",
    "            nCZ = nCZ,\n",
    "            L = L,\n",
    "            initializer = initializer,\n",
    "            ).to(device)\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 2000\n",
    "step_size = 100\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9b82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_normalizer.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "myloss = LpLoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f129d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_865490/637546348.py:68: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  x_fft = torch.rfft(x, 3, normalized=True, onesided=True)\n",
      "/tmp/ipykernel_865490/637546348.py:92: UserWarning: The function torch.irfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.irfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:602.)\n",
      "  x = torch.irfft(out_ft, 3, normalized=True, onesided=True, signal_sizes=(Nx, Ny, T))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train l2 = 0.2233909274339676, test l2 = 0.12907073259353638\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     train_l2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlossFn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_proc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_normalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(train_l2)\n\u001b[1;32m     10\u001b[0m     test_l2 \u001b[38;5;241m=\u001b[39m test(model, test_loader, device, \n\u001b[1;32m     11\u001b[0m         lossFn\u001b[38;5;241m=\u001b[39mmyloss, \n\u001b[1;32m     12\u001b[0m         post_proc\u001b[38;5;241m=\u001b[39my_normalizer\u001b[38;5;241m.\u001b[39mdecode)\n",
      "File \u001b[0;32m~/mnt/mwt/models/utils_3d.py:209\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device, verbose, lossFn, lr_schedule, post_proc)\u001b[0m\n\u001b[1;32m    206\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    207\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 209\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m target \u001b[38;5;241m=\u001b[39m post_proc(target)\n\u001b[1;32m    212\u001b[0m output \u001b[38;5;241m=\u001b[39m post_proc(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [6], line 258\u001b[0m, in \u001b[0;36mMWT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    255\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnCZ):\n\u001b[0;32m--> 258\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMWT_CZ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBN[i](x\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, Nx, Ny, T))\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    260\u001b[0m         B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, Nx, Ny, T)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnCZ\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [6], line 172\u001b[0m, in \u001b[0;36mMWT_CZ.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ns\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL):\n\u001b[1;32m    171\u001b[0m     d, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwavelet_transform(x)\n\u001b[0;32m--> 172\u001b[0m     Ud \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB(x)]\n\u001b[1;32m    173\u001b[0m     Us \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC(d)]\n\u001b[1;32m    174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT0(x\u001b[38;5;241m.\u001b[39mreshape(B, c\u001b[38;5;241m*\u001b[39mich, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    175\u001b[0m     B, c, ich, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, T) \u001b[38;5;66;03m# coarsest scale transform\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [6], line 86\u001b[0m, in \u001b[0;36msparseKernelFT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m out_ft[:, :, :l1, :l2, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes] \u001b[38;5;241m=\u001b[39m compl_mul3d(\n\u001b[1;32m     83\u001b[0m     x_fft[:, :, :l1, :l2, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights1[:, :, :l1, :l2, :])\n\u001b[1;32m     84\u001b[0m out_ft[:, :, \u001b[38;5;241m-\u001b[39ml1:, :l2, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes] \u001b[38;5;241m=\u001b[39m compl_mul3d(\n\u001b[1;32m     85\u001b[0m         x_fft[:, :, \u001b[38;5;241m-\u001b[39ml1:, :l2, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights2[:, :, :l1, :l2, :])\n\u001b[0;32m---> 86\u001b[0m out_ft[:, :, :l1, \u001b[38;5;241m-\u001b[39ml2:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes] \u001b[38;5;241m=\u001b[39m \u001b[43mcompl_mul3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_fft\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights3\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43ml2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m out_ft[:, :, \u001b[38;5;241m-\u001b[39ml1:, \u001b[38;5;241m-\u001b[39ml2:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes] \u001b[38;5;241m=\u001b[39m compl_mul3d(\n\u001b[1;32m     89\u001b[0m         x_fft[:, :, \u001b[38;5;241m-\u001b[39ml1:, \u001b[38;5;241m-\u001b[39ml2:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights4[:, :, :l1, :l2, :])\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#Return to physical space\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [6], line 33\u001b[0m, in \u001b[0;36mcompl_mul3d\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompl_mul3d\u001b[39m(a, b):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     op \u001b[38;5;241m=\u001b[39m partial(torch\u001b[38;5;241m.\u001b[39meinsum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbixyz,ioxyz->boxyz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m---> 33\u001b[0m         \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m op(a[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m], b[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     34\u001b[0m         op(a[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m], b[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m op(a[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m], b[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     35\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/functional.py:344\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    train_l2 = train(model, train_loader, optimizer, epoch, device,\n",
    "        lossFn = myloss, lr_schedule = scheduler,\n",
    "        post_proc = y_normalizer.decode)\n",
    "    train_loss.append(train_l2)\n",
    "    \n",
    "    test_l2 = test(model, test_loader, device, \n",
    "        lossFn=myloss, \n",
    "        post_proc=y_normalizer.decode)\n",
    "    test_loss.append(test_l2)\n",
    "        \n",
    "    if epoch%50 == 0:\n",
    "        PATH = 'NS_models/oldData/NS_model{}.pt'.format(epoch)\n",
    "        torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': myloss}, PATH)\n",
    "        np.save('visual/train_loss_no_experiment.npy', train_loss)\n",
    "        np.save('visual/test_loss_no_experiment.npy', test_loss)\n",
    "    print(f'epoch: {epoch}, train l2 = {train_l2}, test l2 = {test_l2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PATH = 'NS_models/newData/NS_model1300.pt'\n",
    "# PATH = 'NS_models/tryout/NS_model900.pt'\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffaf86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, test_u), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        out = model(x)\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        print(index, test_l2)\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de07733",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0.\n",
    "predictions = []\n",
    "post_proc=y_normalizer.decode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        bs = len(data)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        output = post_proc(output)\n",
    "\n",
    "        loss = myloss(output.view(bs, -1), target.view(bs, -1))\n",
    "        predictions.extend(output.cpu().data.numpy())\n",
    "        total_loss += loss.sum().item()\n",
    "\n",
    "predictions = torch.Tensor(predictions)\n",
    "predictions = torch.reshape(predictions, test_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_test[0].shape', x_test[0].shape)\n",
    "print('x_test.mean(4).shape', x_test.mean(4)[0].shape)\n",
    "print('test_u[0].shape', test_u[0].shape)\n",
    "print('predictions', predictions.shape)\n",
    "print('total loss = ', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.cpu().detach().numpy()\n",
    "# plt.matshow(x[0][:,:,21].T)\n",
    "# plt.matshow(test_u[0][:,:,39].T)\n",
    "# plt.matshow(predictions[0][:,:,39].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307606f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_loss(x_test, predictions, test_u, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba123a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_loss, mean, std = find_loss(predictions, test_u, 0, 0)\n",
    "norm_loss = norm_loss.cpu().detach().numpy()\n",
    "noise = np.random.normal(0, std, norm_loss.shape)\n",
    "print('norm_loss = ', norm_loss)\n",
    "print('mean = ', mean)\n",
    "print('std = ', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061314ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.psd(norm_loss, label = 'loss')\n",
    "plt.psd(noise, label = 'noise')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd1 = np.fft.fft2(norm_loss, norm = 'ortho')\n",
    "psd2 = np.fft.fft2(noise, norm = 'ortho')\n",
    "\n",
    "# plt.matshow(np.abs(psd2))\n",
    "# plt.matshow(np.angle(psd2))\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 18))\n",
    "cp1 = ax[0, 0].matshow(np.abs(psd1)/np.abs(psd1).max())\n",
    "ax[0, 0].set_title('Magnitude of Loss in frequency domain ', fontsize=20)\n",
    "ax[0, 0].xaxis.set_tick_params(labelsize=18)\n",
    "ax[0, 0].yaxis.set_tick_params(labelsize=18)\n",
    "cp1 = fig.colorbar(cp1)\n",
    "cp1.ax.tick_params(labelsize=18)\n",
    "\n",
    "\n",
    "cp2 = ax[0, 1].matshow(np.abs(psd2)/np.abs(psd2).max())\n",
    "ax[0, 1].set_title('Magnitude of Noise in frequency domain ', fontsize=20)\n",
    "ax[0, 1].xaxis.set_tick_params(labelsize=18)\n",
    "ax[0, 1].yaxis.set_tick_params(labelsize=18)\n",
    "cp2 = fig.colorbar(cp2)\n",
    "cp2.ax.tick_params(labelsize=18)\n",
    "\n",
    "cp3 = ax[1, 0].matshow(np.angle(psd1)/np.pi)\n",
    "ax[1, 0].set_title('Phase of Loss in frequency domain ', fontsize=20)\n",
    "ax[1, 0].xaxis.set_tick_params(labelsize=18)\n",
    "ax[1, 0].yaxis.set_tick_params(labelsize=18)\n",
    "cp3 = fig.colorbar(cp3)\n",
    "cp3.ax.tick_params(labelsize=18)\n",
    "\n",
    "\n",
    "cp4 = ax[1, 1].matshow(np.angle(psd2)/np.pi)\n",
    "ax[1, 1].set_title('Phase of Noise in frequency domain ', fontsize=20)\n",
    "ax[1, 1].xaxis.set_tick_params(labelsize=18)\n",
    "ax[1, 1].yaxis.set_tick_params(labelsize=18)\n",
    "cp4 = fig.colorbar(cp4)\n",
    "cp4.ax.tick_params(labelsize=18)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(psd1[0], label = 'loss')\n",
    "# plt.plot(psd2[0], label = 'noise')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffa159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"data\"\n",
    "# image = np.asarray(Image.open(file_path).convert('L'))\n",
    "# freq = np.fft.fft2(image)\n",
    "# freq = np.abs(freq)\n",
    "\n",
    "freq = np.fft.fft2(norm_loss)\n",
    "freq = np.abs(freq)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(14, 6))\n",
    "ax[0,0].hist(np.log(freq.ravel()), bins=100)\n",
    "ax[0,0].set_title('hist(freq)')\n",
    "ax[0,1].hist(np.log(freq).ravel(), bins=100)\n",
    "ax[0,1].set_title('hist(log(freq))')\n",
    "ax[1,0].imshow(np.log(freq), interpolation=\"none\")\n",
    "ax[1,0].set_title('log(freq)')\n",
    "ax[1,1].imshow(norm_loss, interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_l2 = test(model, test_loader, device, lossFn=myloss, post_proc=y_normalizer.decode)\n",
    "# test_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tns = predictions\n",
    "# for set in range(tns.shape[0]):\n",
    "#     makeVid(tns, set, 'animations/NS/ns_V1e-3_N5000_T50/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb44df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tns = test_u\n",
    "# for set in range(tns.shape[0]):\n",
    "#     makeVid(tns, set, 'animations/NS/ns_V1e-3_N5000_T50/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890db3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
