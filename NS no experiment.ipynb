{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95733c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# os.environ['export OPENBLAS_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158373af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import cv2\n",
    "import glob\n",
    "from functools import partial\n",
    "\n",
    "# from models.utils import train, test, LpLoss, get_filter, UnitGaussianNormalizer\n",
    "from models.utils_3d import train, test, LpLoss, get_filter, UnitGaussianNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8ac05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set fraction of GPU you want to use (out of 24GB). 0 denotes the physical GPU number 0 (the only one).\n",
    "# torch.cuda.set_per_process_memory_fraction(0.6, 0)\n",
    "# torch.cuda.empty_cache()\n",
    "# total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "# print('totoal_memory = ', total_memory/10**9)\n",
    "# #anything greater or equal to 0.1 will return an error.\n",
    "# tmp_tensor = torch.empty(int(total_memory * 0.0999), dtype=torch.int8, device='cuda')\n",
    "# del tmp_tensor\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e20d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfaf0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612aca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(name):\n",
    "    \n",
    "    if name == 'xavier_normal':\n",
    "        init_ = partial(nn.init.xavier_normal_)\n",
    "    elif name == 'kaiming_uniform':\n",
    "        init_ = partial(nn.init.kaiming_uniform_)\n",
    "    elif name == 'kaiming_normal':\n",
    "        init_ = partial(nn.init.kaiming_normal_)\n",
    "    return init_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c880e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseKernel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1, \n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernel,self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.conv = self.convBlock(alpha*k**2, alpha*k**2)\n",
    "        self.Lo = nn.Conv1d(alpha*k**2, c*k**2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, ich, Nx, Ny, T)\n",
    "        x = x.reshape(B, -1, Nx, Ny, T)\n",
    "        x = self.conv(x)\n",
    "        x = self.Lo(x.view(B, c*ich, -1)).view(B, c, ich, Nx, Ny, T)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def convBlock(self, ich, och):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv3d(och, och, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return net \n",
    "\n",
    "\n",
    "\n",
    "# fft conv taken from: https://github.com/zongyi-li/fourier_neural_operator\n",
    "def compl_mul3d(a, b):\n",
    "    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "    # print('inputs shape', a.shape)\n",
    "    # print('weights shape', b.shape)\n",
    "    return torch.einsum(\"bixyz,ioxyz->boxyz\", a, b)\n",
    "\n",
    "\n",
    "\n",
    "class sparseKernelFT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1, \n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernelFT, self).__init__()        \n",
    "        \n",
    "        self.modes = alpha\n",
    "\n",
    "        self.weights1 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, dtype=torch.cfloat))        \n",
    "        self.weights3 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, dtype=torch.cfloat))        \n",
    "        self.weights4 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, dtype=torch.cfloat))        \n",
    "        nn.init.xavier_normal_(self.weights1)\n",
    "        nn.init.xavier_normal_(self.weights2)\n",
    "        nn.init.xavier_normal_(self.weights3)\n",
    "        nn.init.xavier_normal_(self.weights4)\n",
    "        \n",
    "        self.Lo = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "#         self.Wo = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "        self.k = k\n",
    "        \n",
    "        \n",
    "    # fft conv taken from: https://github.com/zongyi-li/fourier_neural_operator\n",
    "    def compl_mul3d(self, a, b):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        # print('inputs shape', a.shape)\n",
    "        # print('weights shape', b.shape)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", a, b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, ich, N, N, T)\n",
    "        \n",
    "        # print('x', x.shape)\n",
    "        x = x.reshape(B, -1, Nx, Ny, T)\n",
    "        # print('x reshaped', x.shape)\n",
    "\n",
    "        x_fft = torch.fft.rfft(x)\n",
    "        # print('x_fft', x_fft.shape)\n",
    "        \n",
    "        # Multiply relevant Fourier modes\n",
    "        l1 = min(self.modes, Nx//2+1)\n",
    "        l2 = min(self.modes, Ny//2+1)\n",
    "        \n",
    "        out_ft = torch.zeros(B, c*ich, Nx, Ny, T//2 +1, dtype=torch.cfloat, device=x.device)\n",
    "        # print('out_ft', out_ft.shape)\n",
    "\n",
    "        \n",
    "        out_ft[:, :, :l1, :l2, :self.modes] = self.compl_mul3d(\n",
    "            x_fft[:, :, :l1, :l2, :self.modes], self.weights1[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, -l1:, :l2, :self.modes] = self.compl_mul3d(\n",
    "                x_fft[:, :, -l1:, :l2, :self.modes], self.weights2[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, :l1, -l2:, :self.modes] = self.compl_mul3d(\n",
    "                x_fft[:, :, :l1, -l2:, :self.modes], self.weights3[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, -l1:, -l2:, :self.modes] = self.compl_mul3d(\n",
    "                x_fft[:, :, -l1:, -l2:, :self.modes], self.weights4[:, :, :l1, :l2, :])\n",
    "        \n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft(out_ft)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.Lo(x.view(B, c*ich, -1)).view(B, c, ich, Nx, Ny, T)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MWT_CZ(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k = 3, alpha = 5, \n",
    "                 L = 0, c = 1,\n",
    "                 base = 'legendre',\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(MWT_CZ, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0@PHI0\n",
    "        G0r = G0@PHI0\n",
    "        H1r = H1@PHI1\n",
    "        G1r = G1@PHI1\n",
    "        \n",
    "        H0r[np.abs(H0r)<1e-8]=0\n",
    "        H1r[np.abs(H1r)<1e-8]=0\n",
    "        G0r[np.abs(G0r)<1e-8]=0\n",
    "        G1r[np.abs(G1r)<1e-8]=0\n",
    "        \n",
    "        self.A = sparseKernelFT(k, alpha, c)\n",
    "        self.B = sparseKernelFT(k, alpha, c)\n",
    "        self.C = sparseKernelFT(k, alpha, c)\n",
    "        \n",
    "        self.T0 = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "\n",
    "        if initializer is not None:\n",
    "            self.reset_parameters(initializer)\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0, H0).T, \n",
    "                            np.kron(H0, H1).T,\n",
    "                            np.kron(H1, H0).T,\n",
    "                            np.kron(H1, H1).T,\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((np.kron(G0, G0).T,\n",
    "                            np.kron(G0, G1).T,\n",
    "                            np.kron(G1, G0).T,\n",
    "                            np.kron(G1, G1).T,\n",
    "                           ), axis=0)))\n",
    "        \n",
    "        self.register_buffer('rc_ee', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0r, H0r), \n",
    "                            np.kron(G0r, G0r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_eo', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0r, H1r), \n",
    "                            np.kron(G0r, G1r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_oe', torch.Tensor(\n",
    "            np.concatenate((np.kron(H1r, H0r), \n",
    "                            np.kron(G1r, G0r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_oo', torch.Tensor(\n",
    "            np.concatenate((np.kron(H1r, H1r), \n",
    "                            np.kron(G1r, G1r),\n",
    "                           ), axis=0)))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, k^2, Nx, Ny, T)\n",
    "        ns = math.floor(np.log2(Nx))\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "#         decompose\n",
    "        for i in range(ns-self.L):\n",
    "            d, x = self.wavelet_transform(x)\n",
    "            Ud += [self.A(d) + self.B(x)]\n",
    "            Us += [self.C(d)]\n",
    "        x = self.T0(x.reshape(B, c*ich, -1)).view(\n",
    "            B, c, ich, 2**self.L, 2**self.L, T) # coarsest scale transform\n",
    "\n",
    "#        reconstruct            \n",
    "        for i in range(ns-1-self.L,-1,-1):\n",
    "            x = x + Us[i]\n",
    "            x = torch.cat((x, Ud[i]), 2)\n",
    "            x = self.evenOdd(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, :, :, ::2 , ::2 , :], \n",
    "                        x[:, :, :, ::2 , 1::2, :], \n",
    "                        x[:, :, :, 1::2, ::2 , :], \n",
    "                        x[:, :, :, 1::2, 1::2, :]\n",
    "                       ], 2)\n",
    "        waveFil = partial(torch.einsum, 'bcixyt,io->bcoxyt') \n",
    "        d = waveFil(xa, self.ec_d)\n",
    "        s = waveFil(xa, self.ec_s)\n",
    "        return d, s\n",
    "        \n",
    "        \n",
    "    def evenOdd(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, 2*k^2, Nx, Ny)\n",
    "        assert ich == 2*self.k**2\n",
    "        evOd = partial(torch.einsum, 'bcixyt,io->bcoxyt')\n",
    "        x_ee = evOd(x, self.rc_ee)\n",
    "        x_eo = evOd(x, self.rc_eo)\n",
    "        x_oe = evOd(x, self.rc_oe)\n",
    "        x_oo = evOd(x, self.rc_oo)\n",
    "        \n",
    "        x = torch.zeros(B, c, self.k**2, Nx*2, Ny*2, T,\n",
    "            device = x.device)\n",
    "        x[:, :, :, ::2 , ::2 , :] = x_ee\n",
    "        x[:, :, :, ::2 , 1::2, :] = x_eo\n",
    "        x[:, :, :, 1::2, ::2 , :] = x_oe\n",
    "        x[:, :, :, 1::2, 1::2, :] = x_oo\n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self, initializer):\n",
    "        initializer(self.T0.weight)\n",
    "    \n",
    "    \n",
    "class MWT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ich = 1, k = 3, alpha = 2, c = 1,\n",
    "                 nCZ = 3,\n",
    "                 L = 0,\n",
    "                 base = 'legendre',\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(MWT,self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.L = L\n",
    "        self.nCZ = nCZ\n",
    "        self.Lk = nn.Linear(ich, c*k**2)\n",
    "        \n",
    "        self.MWT_CZ = nn.ModuleList(\n",
    "            [MWT_CZ(k, alpha, L, c, base, \n",
    "            initializer) for _ in range(nCZ)]\n",
    "        )\n",
    "        self.BN = nn.ModuleList(\n",
    "            [nn.BatchNorm3d(c*k**2) for _ in range(nCZ)]\n",
    "        )\n",
    "        self.Lc0 = nn.Linear(c*k**2, 128)\n",
    "        self.Lc1 = nn.Linear(128, 1)\n",
    "        \n",
    "        if initializer is not None:\n",
    "            self.reset_parameters(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, Nx, Ny, T, ich = x.shape # (B, Nx, Ny, T, d)\n",
    "        ns = math.floor(np.log2(Nx))\n",
    "        x = model.Lk(x)\n",
    "        x = x.view(B, Nx, Ny, T, self.c, self.k**2)\n",
    "        x = x.permute(0, 4, 5, 1, 2, 3)\n",
    "    \n",
    "        for i in range(self.nCZ):\n",
    "            x = self.MWT_CZ[i](x)\n",
    "            x = self.BN[i](x.view(B, -1, Nx, Ny, T)).view(\n",
    "                B, self.c, self.k**2, Nx, Ny, T)\n",
    "            if i < self.nCZ-1:\n",
    "                x = F.relu(x)\n",
    "\n",
    "        x = x.view(B, -1, Nx, Ny, T) # collapse c and k**2\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = self.Lc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.Lc1(x)\n",
    "        return x.squeeze()\n",
    "    \n",
    "    def reset_parameters(self, initializer):\n",
    "        initializer(self.Lc0.weight)\n",
    "        initializer(self.Lc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9026c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVid(tensor, set, dirPath):\n",
    "    \n",
    "    newDir = 'train{}'.format(set)\n",
    "    path = os.path.join(dirPath, newDir)\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    for i in range(tensor.shape[-1]):\n",
    "        f = tensor[set][:, :, i]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(f, interpolation='nearest')\n",
    "        cbar = fig.colorbar(cax)\n",
    "        \n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        cbar.set_label('Vorticity (RPM)', rotation=270)\n",
    "        ax.set_title('Two-dimensional Vorticity')\n",
    "        plt.savefig(path+'/{}.png'.format(i))\n",
    "    \n",
    "    img_array = []\n",
    "    filelist = glob.glob(path+'/*.png')\n",
    "    \n",
    "    for filename in sorted(filelist):\n",
    "        img = cv2.imread(filename)\n",
    "        print(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "    \n",
    "    fps = 1\n",
    "    vids = os.path.join(dirPath, 'videos')\n",
    "    if os.path.isdir(vids):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(vids)\n",
    "\n",
    "    vidpath = vids+'/Vid{}.mp4'.format(set)\n",
    "    out = cv2.VideoWriter(vidpath ,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "    for j in range(len(img_array)):\n",
    "        out.write(img_array[j])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bcadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/ns_V1e-3_N5000_T50.mat'\n",
    "\n",
    "ntrain = 1000\n",
    "ntest = 200\n",
    "\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8dded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 64, 64, 10])\n",
      "torch.Size([1000, 64, 64, 40])\n",
      "torch.Size([200, 64, 64, 10])\n",
      "torch.Size([200, 64, 64, 40])\n"
     ]
    }
   ],
   "source": [
    "sub = 1\n",
    "S = 64 // sub\n",
    "T_in = 10\n",
    "T = 40\n",
    "\n",
    "dataloader = h5py.File(data_path)\n",
    "u_data = dataloader['u']\n",
    "t_data = dataloader['t']\n",
    "\n",
    "\n",
    "train_a = torch.from_numpy(u_data[:T_in, ::sub,::sub,:ntrain]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "train_u = torch.from_numpy(u_data[T_in:T_in+T, ::sub,::sub,:ntrain]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "\n",
    "test_a = torch.from_numpy(u_data[:T_in, ::sub,::sub,-ntest:]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "test_u = torch.from_numpy(u_data[T_in:T_in+T, ::sub,::sub,-ntest:]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "\n",
    "print(train_a.shape)\n",
    "print(train_u.shape)\n",
    "print(test_a.shape)\n",
    "print(test_u.shape)\n",
    "assert(S == train_u.shape[-2])\n",
    "assert(T == train_u.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "295bb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tns = train_a\n",
    "# for set in range(tns.shape[0]):\n",
    "#     makeVid(tns, set, 'animations/NS/ns_V1e-3_N5000_T50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6946bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 64, 64, 40])\n",
      "x_train shape before =  torch.Size([1000, 64, 64, 10])\n",
      "x_test shape before =  torch.Size([200, 64, 64, 10])\n",
      "x_train shape after =  torch.Size([1000, 64, 64, 40, 10])\n",
      "x_test shape after =  torch.Size([200, 64, 64, 40, 10])\n"
     ]
    }
   ],
   "source": [
    "a_normalizer = UnitGaussianNormalizer(train_a)\n",
    "x_train0 = a_normalizer.encode(train_a)\n",
    "x_test0 = a_normalizer.encode(test_a)\n",
    "\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(train_u)\n",
    "y_train = y_normalizer.encode(train_u)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print('x_train shape before = ', x_train0.shape)\n",
    "print('x_test shape before = ', x_test0.shape)\n",
    "\n",
    "x_train0 = x_train0.reshape(ntrain,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "x_test0 = x_test0.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "\n",
    "print('x_train shape after = ', x_train0.shape)\n",
    "print('x_test shape after = ', x_test0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188e2a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridx shape =  torch.Size([1, 64, 64, 40, 1])\n",
      "gridy shape =  torch.Size([1, 64, 64, 40, 1])\n",
      "gridt shape =  torch.Size([1, 64, 64, 40, 1])\n",
      "x_train shape before =  torch.Size([1000, 64, 64, 40, 10])\n",
      "x_train shape after =  torch.Size([1000, 64, 64, 40, 13])\n",
      "x_test shape before =  torch.Size([200, 64, 64, 40, 10])\n",
      "x_test shape after =  torch.Size([200, 64, 64, 40, 13])\n"
     ]
    }
   ],
   "source": [
    "# pad locations (x,y,t)\n",
    "gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridx = gridx.reshape(1, S, 1, 1, 1).repeat([1, 1, S, T, 1])\n",
    "print('gridx shape = ', gridx.shape)\n",
    "gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridy = gridy.reshape(1, 1, S, 1, 1).repeat([1, S, 1, T, 1])\n",
    "print('gridy shape = ', gridy.shape)\n",
    "gridt = torch.tensor(np.linspace(0, 1, T+1)[1:], dtype=torch.float)\n",
    "gridt = gridt.reshape(1, 1, 1, T, 1).repeat([1, S, S, 1, 1])\n",
    "print('gridt shape = ',gridt.shape)\n",
    "\n",
    "print('x_train shape before = ', x_train0.shape)\n",
    "x_train = torch.cat((gridx.repeat([ntrain,1,1,1,1]), gridy.repeat([ntrain,1,1,1,1]),\n",
    "                       gridt.repeat([ntrain,1,1,1,1]), x_train0), dim=-1)\n",
    "print('x_train shape after = ', x_train.shape)\n",
    "\n",
    "print('x_test shape before = ', x_test0.shape)\n",
    "x_test = torch.cat((gridx.repeat([ntest,1,1,1,1]), gridy.repeat([ntest,1,1,1,1]),\n",
    "                       gridt.repeat([ntest,1,1,1,1]), x_test0), dim=-1)\n",
    "print('x_test shape after = ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b89b17",
   "metadata": {},
   "source": [
    "# Each dimension explained:\n",
    "\n",
    "$gridx$ $shape =  torch.Size([1, 64, 64, 40, 1])$ first $1$ represents the number of subsamples, but not sure why there is a $1$ at the end. $64\\times 64$ is the $x\\times y$ grid and $40$ is the number of future timesteps used for prediction. Same for gridy and gridt\n",
    "\n",
    "$gridy$ $shape =  torch.Size([1, 64, 64, 40, 1])$\n",
    "\n",
    "$gridt$ $shape =  torch.Size([1, 64, 64, 40, 1])$\n",
    "\n",
    "$x\\_train$ $shape$ $before =  torch.Size([1000, 64, 64, 40, 13])$ repeated $ntrain = 1000$ times at the beginning, then \n",
    "\n",
    "\n",
    "$x\\_train$ $shape$ $after =  torch.Size([1000, 64, 64, 40, 13])$\n",
    "\n",
    "$x\\_test$ $shape$ $before =  torch.Size([200, 64, 64, 40, 13])$\n",
    "\n",
    "$x\\_test$ $shape$ $after =  torch.Size([200, 64, 64, 40, 13])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3edfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, test_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce6d2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in test_loader:\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755b607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ich = 13\n",
    "initializer = get_initializer('xavier_normal') # xavier_normal, kaiming_normal, kaiming_uniform\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "alpha = 12\n",
    "c = 4\n",
    "k = 3\n",
    "nCZ = 4\n",
    "L = 0\n",
    "model = MWT(ich, \n",
    "            alpha = alpha,\n",
    "            c = c,\n",
    "            k = k, \n",
    "            base = 'legendre', # chebyshev\n",
    "            nCZ = nCZ,\n",
    "            L = L,\n",
    "            initializer = initializer,\n",
    "            ).to(device)\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 2000\n",
    "step_size = 100\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f056268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_normalizer.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "myloss = LpLoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f686841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = 'NS_models/NS_model1600.pt'\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15522a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 23.69 GiB total capacity; 1.83 GiB already allocated; 99.12 MiB free; 1.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     train_l2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlossFn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_proc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_normalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(train_l2)\n\u001b[1;32m     10\u001b[0m     test_l2 \u001b[38;5;241m=\u001b[39m test(model, test_loader, device, \n\u001b[1;32m     11\u001b[0m         lossFn\u001b[38;5;241m=\u001b[39mmyloss, \n\u001b[1;32m     12\u001b[0m         post_proc\u001b[38;5;241m=\u001b[39my_normalizer\u001b[38;5;241m.\u001b[39mdecode)\n",
      "File \u001b[0;32m~/mnt/mwt/models/utils_3d.py:209\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device, verbose, lossFn, lr_schedule, post_proc)\u001b[0m\n\u001b[1;32m    206\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    207\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 209\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m target \u001b[38;5;241m=\u001b[39m post_proc(target)\n\u001b[1;32m    212\u001b[0m output \u001b[38;5;241m=\u001b[39m post_proc(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [7], line 312\u001b[0m, in \u001b[0;36mMWT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnCZ):\n\u001b[0;32m--> 312\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMWT_CZ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBN[i](x\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, Nx, Ny, T))\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    314\u001b[0m         B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, Nx, Ny, T)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnCZ\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [7], line 227\u001b[0m, in \u001b[0;36mMWT_CZ.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    225\u001b[0m             d, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwavelet_transform(x)\n\u001b[1;32m    226\u001b[0m             Ud \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA(d) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB(x)]\n\u001b[0;32m--> 227\u001b[0m             Us \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    228\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT0(x\u001b[38;5;241m.\u001b[39mreshape(B, c\u001b[38;5;241m*\u001b[39mich, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    229\u001b[0m             B, c, ich, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, T) \u001b[38;5;66;03m# coarsest scale transform\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m#        reconstruct            \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [7], line 99\u001b[0m, in \u001b[0;36msparseKernelFT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m out_ft[:, :, \u001b[38;5;241m-\u001b[39ml1:, \u001b[38;5;241m-\u001b[39ml2:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompl_mul3d(\n\u001b[1;32m     96\u001b[0m         x_fft[:, :, \u001b[38;5;241m-\u001b[39ml1:, \u001b[38;5;241m-\u001b[39ml2:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights4[:, :, :l1, :l2, :])\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#Return to physical space\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mirfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_ft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    102\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLo(x\u001b[38;5;241m.\u001b[39mview(B, c\u001b[38;5;241m*\u001b[39mich, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(B, c, ich, Nx, Ny, T)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 23.69 GiB total capacity; 1.83 GiB already allocated; 99.12 MiB free; 1.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    train_l2 = train(model, train_loader, optimizer, epoch, device,\n",
    "        lossFn = myloss, lr_schedule = scheduler,\n",
    "        post_proc = y_normalizer.decode)\n",
    "    train_loss.append(train_l2)\n",
    "    \n",
    "    test_l2 = test(model, test_loader, device, \n",
    "        lossFn=myloss, \n",
    "        post_proc=y_normalizer.decode)\n",
    "    test_loss.append(test_l2)\n",
    "        \n",
    "    if epoch%100 == 0:\n",
    "        PATH = 'NS_model{}.pt'.format(epoch)\n",
    "        torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': myloss}, PATH)\n",
    "        np.save('train_loss_no_experiment.npy', train_loss)\n",
    "        np.save('test_loss_no_experiment.npy', test_loss)\n",
    "    print(f'epoch: {epoch}, train l2 = {train_l2}, test l2 = {test_l2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label = 'train loss')\n",
    "plt.plot(test_loss, label = 'test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a095a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = 'NS_model2000.pt'\n",
    "# torch.save({'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': myloss}, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, test_u), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        out = model(x)\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        print(index, test_l2)\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "# for x, y in test_loader:\n",
    "    # Shapes is 1024 inputs (x) and 1024 outputs (y)\n",
    "#     print(x[0].shape)\n",
    "#     print(y[0].shape)\n",
    "    # plt.matshow(x[0][:, :, 0])\n",
    "    #plt.matshow(y[0][:, :, 0])\n",
    "\n",
    "    # Create plots with pre-defined labels.    \n",
    "#     fig, ax = plt.subplots()\n",
    "#     fig.set_figwidth(14)\n",
    "#     fig.set_figheight(8)\n",
    "#     ax.plot(x[0], label='Initial conditions $u(x,t)$ where $t \\in$ [0,1024]')\n",
    "#     ax.plot(pred[index], label='Predicted evolution $(t \\in [1025,2048])$')\n",
    "#     ax.plot(y[0], 'k--', label='Real evolution $(t \\in [1025,2048])$')\n",
    "#     index += 1\n",
    "#     legend = ax.legend(loc='lower right', shadow=True)\n",
    "#     ax.set_xlabel(\"Initial condition index\")\n",
    "#     ax.set_ylabel(\"Initial condition value u(x,t)\")\n",
    "#     ax.set_title(\"Time evolution of initial conditions\")\n",
    "#     ax.grid()\n",
    "    \n",
    "    # Put a nicer background color on the legend.\n",
    "    # legend.get_frame().set_facecolor('C0')\n",
    "    # plt.savefig('/content/drive/MyDrive/IIB project/mwt/ip-op/fig{}.png'.format(index))\n",
    "    # files.download(\"/content/drive/MyDrive/IIB project/mwt/ip-op/fig{}.png\".format(index)) \n",
    "    # plt.clf()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51537b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test[0].shape)\n",
    "x = x_test.mean(4)\n",
    "print(x[0].shape)\n",
    "print(test_u[0].shape)\n",
    "print(pred[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b912d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(prediction, test, index, timestep):\n",
    "    test = test[index][:, :, timestep]\n",
    "    prediction = torch.t(prediction[index][:, :, timestep])\n",
    "    loss = torch.sub(test, prediction)\n",
    "    \n",
    "    print(test)\n",
    "    print(prediction)\n",
    "    print(loss)\n",
    "    \n",
    "    plt.matshow(test)\n",
    "    plt.matshow(prediction)\n",
    "    plt.matshow(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(pred, test_u, 10, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
